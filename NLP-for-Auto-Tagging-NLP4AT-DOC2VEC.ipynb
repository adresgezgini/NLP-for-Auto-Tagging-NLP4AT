{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-for-Auto-Tagging-NLP4AT-DOC2VEC",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh3IRlNKFl7Y"
      },
      "source": [
        "Model için gereken kütüphaneleri yükleriz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIRay2BfM8He"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import multiprocessing\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import nltk\r\n",
        "from gensim.models.doc2vec import TaggedDocument\r\n",
        "from gensim.models import Doc2Vec,doc2vec\r\n",
        "from tqdm import tqdm\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score, f1_score, plot_confusion_matrix, confusion_matrix\r\n",
        "import scikitplot as skplt\r\n",
        "from sklearn import metrics,utils\r\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apdJM3oIFpiu"
      },
      "source": [
        "Veri setimizin yüklemesini gerçekleştiririz\r\n",
        "Mecvut analizimiz için bir kolonda verinin kendisi, diğer kolonda ise verinin etiketinin bulunması yeterlidir.\r\n",
        "text,\tlabels\r\n",
        "\r\n",
        "\tmağazamın ınstagram hesabı için reklam vermeyi...\t4\r\n",
        "\tgoogle şirket reklamı vermek istiyordum bu kon...\t2\r\n",
        "\tben ınstagram\t4\r\n",
        "\tkolay glsin ben web siteme reklam almak istiyo...\t2\r\n",
        "\tsitemin trafiğini arttırmak için reklam vermey...\t0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC-HAsZRJhlU"
      },
      "source": [
        "train = pd.read_csv('veriseti.csv')\n",
        "train = train[['text','labels']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG07VCtDFuqW"
      },
      "source": [
        "Veri setimizi eğitim ve test veri seti olarak ayırırız"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZNyTRqYeqG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train1,test1 = train_test_split(train, test_size = 0.3, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwISvo2OFylo"
      },
      "source": [
        "Burada veri setimizi modelin analizine daha uygun bir hale getirmek için noktalama işaretlerinden, sembollerden, bozuk karakterlerden ayırıp, büyük harfleri küçük harf haline getiren bir fonksyon oluşturuyoruz ve veri setimize bunu uyguluyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5exJ5oR0jM9c"
      },
      "source": [
        "import re\r\n",
        "def cleanText(input_sentence):\r\n",
        " \r\n",
        "  tmp= [word.replace('I','ı') for word in input_sentence.split(' ')]\r\n",
        "  tmp= [word.lower() for word in tmp]\r\n",
        "  tmp= [word.replace('i̇','i') for word in tmp]\r\n",
        "  tmp = [re.sub('[^A-Za-z0-9ğüşıçöiâî]+', ' ', word) for word in tmp]\r\n",
        "  tmp = [word.strip(' ') for word in tmp]\r\n",
        "  tmp1 =' '.join(tmp)\r\n",
        "\r\n",
        "  return tmp1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUF8I0EIjtto"
      },
      "source": [
        "train1['text']=train1['text'].apply(cleanText)\r\n",
        "test1['text']=test1['text'].apply(cleanText)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnqIWwipGNyZ"
      },
      "source": [
        "NLTK Kütüphanesi ile veri setimizi analiz öncesi tokenize ediyoruz. Bunu yaparken eğitim ve test veri setlerimizdeki sorgu, sonuna etiketi eklenmiş bir hale dönüşüyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXigxY5I9Zs9"
      },
      "source": [
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word.lower())\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0DXos50RaY-"
      },
      "source": [
        "train_tagged = train1.apply(lambda r: TaggedDocument(words=tokenize_text(r['text']), tags=[r.labels]), axis=1)\r\n",
        "test_tagged = test1.apply(lambda r: TaggedDocument(words=tokenize_text(r['text']), tags=[r.labels]), axis=1)\r\n",
        "tr_tags = [i.tags[0] for i in train_tagged]\r\n",
        "te_tags = [i.tags[0] for i in test_tagged] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJhKxnroGc-D"
      },
      "source": [
        "Burada lojistik regresyon analizi ve destek vektör makineleri yöntemleri ile sınıflandırma yapan iki ayrı fonksyon tanımlıyoruz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ep7ODsrmFpp"
      },
      "source": [
        "Lojistik Regresyon Sonuçları Fonksyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7xpMRsfhnM7"
      },
      "source": [
        "def LogReg_Results(train_embeddings,test_embeddings):\r\n",
        "  logreg = LogisticRegression(n_jobs=cores, C = 10000, max_iter=10000, tol = 1e-5)\r\n",
        "  logreg.fit(train_embeddings, tr_tags)    \r\n",
        "  te_tags_predicted = logreg.predict(test_embeddings)\r\n",
        "  tr_tags_predicted = logreg.predict(train_embeddings)\r\n",
        "\r\n",
        "  print('Train accuracy %s' % accuracy_score(tr_tags, tr_tags_predicted))\r\n",
        "  print('Testing accuracy %s' % accuracy_score(te_tags, te_tags_predicted))\r\n",
        "  print('Testing Log-Reg F1 weighted score: {}'.format(f1_score(te_tags, te_tags_predicted, average='weighted')))\r\n",
        "  print('Testing Log-Reg F1 macro score: {}'.format(f1_score(te_tags, te_tags_predicted, average='macro')))\r\n",
        "  print('Testing Log-Reg F1 macro score class-based:: {}'.format(f1_score(te_tags, te_tags_predicted, average=None)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4d0Q10alzA7"
      },
      "source": [
        "C-Destek Vektör Makineleri Sonucu Fonksyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T39N-4ygys_"
      },
      "source": [
        "def SVC_Results(train_embeddings,test_embeddings):\r\n",
        "  clf = SVC(kernel='linear', C=1).fit(train_embeddings, tr_tags)\r\n",
        "  clf_te_tags_predicted = clf.predict(test_embeddings)    \r\n",
        "  clf_tr_tags_predicted = clf.predict(train_embeddings)\r\n",
        "  \r\n",
        "  print('C-SVC Train Score %s\\n'%clf.score(train_embeddings, tr_tags))\r\n",
        "  print('C-SVC Test Score %s\\n'%clf.score(test_embeddings, te_tags))\r\n",
        "  print('Testing C-SVC F1 weighted score: {}'.format(f1_score(te_tags, clf_te_tags_predicted, average='weighted')))\r\n",
        "  print('Testing C-SVC F1 macro score: {}'.format(f1_score(te_tags, clf_te_tags_predicted, average='macro')))\r\n",
        "  print('Testing C-SVC F1 macro score class-based:: {}'.format(f1_score(te_tags, clf_te_tags_predicted, average=None)))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdeNvt3pGomb"
      },
      "source": [
        "Modelimizi farklı vektör genişliklerinde, farklı iterasyon sayılarında ve farklı model çeşitlerinde birbirine göre eğitmek için iç içe bir döngü oluşturuyoruz. Bu işlem uzun sürmektedir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb54rgrN86kA"
      },
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "for vs in [10,20,30,50,75,100,125,175,200,350,500,750,1000,1250,1500,2000]:  \n",
        "  for epoch in [1,2,3,4,10]:\n",
        "    for dm in [0,1]:\n",
        "      print('\\n','setting : ','dm : ', dm, 'vs : ', vs, 'num epochs : ', epoch)\n",
        "      model_dm = Doc2Vec(dm=dm, vector_size=vs, window=10, negative=5, min_count=1, workers=cores, alpha=0.0061, min_alpha = 0.0001)\n",
        "      model_dm.build_vocab([x for x in tqdm(train_tagged.values)])\n",
        "\n",
        "      for ep in range(epoch):\n",
        "        model_dm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "        model_dm.alpha -= 0.0012\n",
        "        model_dm.min_alpha = model_dm.alpha\n",
        "      \n",
        "      train_embeddings = [] \n",
        "      for i in train_tagged:\n",
        "        embedding = model_dm.infer_vector(i.words, steps=20, alpha = 0.005)\n",
        "        train_embeddings.append(embedding)        \n",
        "\n",
        "      test_embeddings = [] \n",
        "      for i in test_tagged:\n",
        "        embedding = model_dm.infer_vector(i.words, steps=20, alpha = 0.005)\n",
        "        test_embeddings.append(embedding)     \n",
        "\n",
        "      LogReg_Results(train_embeddings,test_embeddings)\n",
        "      SVC_Results(train_embeddings,test_embeddings)\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
