{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-for-Auto-Tagging-NLP4AT-AdresGezgini-ARGE",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p893NM0iRUjE"
      },
      "source": [
        "# Başlangıç"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbT0vtNwOPXz"
      },
      "source": [
        "Model için gerekli modülleri kurulması"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qo6mJVWNhc8"
      },
      "source": [
        "!pip install scikitplot\r\n",
        "!pip install chart_studio\r\n",
        "!pip install sklearn\r\n",
        "!pip install transformers\r\n",
        "!pip install simpletransformers\r\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5BgqLfOOTpP"
      },
      "source": [
        "Model için gereken kütüphanelerin yüklenmesi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmjnnbKVOXNQ"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import multiprocessing\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import nltk\r\n",
        "from gensim.models.doc2vec import TaggedDocument\r\n",
        "from gensim.models import Doc2Vec,doc2vec\r\n",
        "from tqdm import tqdm\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score, f1_score, plot_confusion_matrix, confusion_matrix\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import umap\r\n",
        "import scikitplot as skplt\r\n",
        "from sklearn import metrics,utils\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from keras.layers import Dropout\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk import word_tokenize\r\n",
        "STOPWORDS = set(stopwords.words('turkish'))\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import plotly.graph_objs as go\r\n",
        "import chart_studio.plotly as py\r\n",
        "import cufflinks\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "import plotly.figure_factory as ff\r\n",
        "InteractiveShell.ast_node_interactivity = 'all'\r\n",
        "from plotly.offline import iplot\r\n",
        "cufflinks.go_offline()\r\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')\r\n",
        "from simpletransformers.classification import ClassificationModel\r\n",
        "import torch,sklearn\r\n",
        "from torch import nn\r\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelForSequenceClassification\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kDJ8BcmRVZf"
      },
      "source": [
        "# Veri Setinin Eklenmesi ve Ön İşleme Tabi Tutulması"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apdJM3oIFpiu"
      },
      "source": [
        "Veri setimizin yüklemesini gerçekleştiririz\r\n",
        "Mecvut analizimiz için bir kolonda verinin kendisi, diğer kolonda ise verinin etiketinin bulunması yeterlidir.\r\n",
        "text,\tlabels\r\n",
        "\r\n",
        "\tmağazamın ınstagram hesabı için reklam vermeyi...\t4\r\n",
        "\tgoogle şirket reklamı vermek istiyordum bu kon...\t2\r\n",
        "\tben ınstagram\t4\r\n",
        "\tkolay glsin ben web siteme reklam almak istiyo...\t2\r\n",
        "\tsitemin trafiğini arttırmak için reklam vermey...\t0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTzXPk-8QYuU"
      },
      "source": [
        "train = pd.read_csv('train.csv')\r\n",
        "test = pd.read_csv('test.csv')\r\n",
        "train = train[['text','labels']]\r\n",
        "test = test[['text','labels']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lALAdKKvanqL"
      },
      "source": [
        "Veri Setimize Göz Atıyoruz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgslsD0Ear8t"
      },
      "source": [
        "Eğitim Seti:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmHUS37_aiWL"
      },
      "source": [
        "import seaborn as sns\r\n",
        "cnt_pro = train['labels'].value_counts()\r\n",
        "\r\n",
        "plt.figure(figsize=(12,4))\r\n",
        "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\r\n",
        "plt.ylabel('Number of Questions', fontsize=12)\r\n",
        "plt.xlabel('labels', fontsize=12)\r\n",
        "plt.xticks(rotation=90)\r\n",
        "plt.savefig('fname', dpi=1200, facecolor='w', edgecolor='w',\r\n",
        "        orientation='portrait', papertype=None, format=None,\r\n",
        "        transparent=False, bbox_inches=None, pad_inches=0.1,\r\n",
        "        frameon=None, metadata=None)\r\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Utq1kmatRh"
      },
      "source": [
        "Test Seti:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7PM-Ac4amzk"
      },
      "source": [
        "import seaborn as sns\r\n",
        "cnt_pro = test['labels'].value_counts()\r\n",
        "\r\n",
        "plt.figure(figsize=(12,4))\r\n",
        "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\r\n",
        "plt.ylabel('Number of Questions', fontsize=12)\r\n",
        "plt.xlabel('labels', fontsize=12)\r\n",
        "plt.xticks(rotation=90)\r\n",
        "plt.savefig('fname', dpi=1200, facecolor='w', edgecolor='w',\r\n",
        "        orientation='portrait', papertype=None, format=None,\r\n",
        "        transparent=False, bbox_inches=None, pad_inches=0.1,\r\n",
        "        frameon=None, metadata=None)\r\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWtrzpToQezg"
      },
      "source": [
        "Veri ön işleme aşamasında, veri setimizi küçük harflere dönüştürüp, noktalama işaretleri ve sembollerden arındırılmış hale getirir ve tokenize ederiz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLgwiC3mQdPo"
      },
      "source": [
        "def cleanText(input_sentence):\r\n",
        " \r\n",
        "  tmp= [word.replace('I','ı') for word in input_sentence.split(' ')]\r\n",
        "  tmp= [word.lower() for word in tmp]\r\n",
        "  tmp= [word.replace('i̇','i') for word in tmp]\r\n",
        "  tmp = [re.sub('[^A-Za-z0-9ğüşıçöiâî]+', ' ', word) for word in tmp]\r\n",
        "  tmp = [word.strip(' ') for word in tmp]\r\n",
        "  tmp1 =' '.join(tmp)\r\n",
        "  return tmp1\r\n",
        "\r\n",
        "#Temizleme fonksyonunun uygulanması\r\n",
        "train['text']=train['text'].apply(cleanText)\r\n",
        "test['text']=test['text'].apply(cleanText)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfG9EDyvR0NC"
      },
      "source": [
        "# Doc2Vec Modeli İle AutoTagging Yapılması"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUS1qNTeRJ4v"
      },
      "source": [
        "Doc2Vec Modeli ile veri setimiz için RandomForest, C-SVC ve Lojistik Regresyon sınıflandırma modelleri denenmiş en iyi sonuç Lojistik Regresyon modelinden alındığı için sınıflandırıcı olarak bu model seçilmiştir. Aşağıda Lojistik Regresyon modelini Doc2Vec embeddinglerine uygulamak ve sonuçları çıktı almak için yazılmış fonksyon bulunmaktadır."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__FtVQH_RHtl"
      },
      "source": [
        "def LogReg_Results(train_embeddings,test_embeddings):\r\n",
        "  logreg = LogisticRegression(n_jobs=cores, C = 10000, max_iter=10000, tol = 1e-5)\r\n",
        "  logreg.fit(train_embeddings, tr_tags)    \r\n",
        "  te_tags_predicted = logreg.predict(test_embeddings)\r\n",
        "  tr_tags_predicted = logreg.predict(train_embeddings)\r\n",
        "\r\n",
        "  print('Train accuracy %s' % accuracy_score(tr_tags, tr_tags_predicted))\r\n",
        "  print('Testing accuracy %s' % accuracy_score(te_tags, te_tags_predicted))\r\n",
        "  print('Testing Log-Reg F1 weighted score: {}'.format(f1_score(te_tags, te_tags_predicted, average='weighted')))\r\n",
        "  print('Testing Log-Reg F1 macro score: {}'.format(f1_score(te_tags, te_tags_predicted, average='macro')))\r\n",
        "  print('Testing Log-Reg F1 macro score class-based:: {}'.format(f1_score(te_tags, te_tags_predicted, average=None)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hJZilJIR-bO"
      },
      "source": [
        "Eğitim ve test veri setini etiketleyip tokenized hale getiriyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGzTyjY9R-zP"
      },
      "source": [
        "def tokenize_text(text):\r\n",
        "    tokens = []\r\n",
        "    for sent in nltk.sent_tokenize(text):\r\n",
        "        for word in nltk.word_tokenize(sent):\r\n",
        "            if len(word) < 2:\r\n",
        "                continue\r\n",
        "            tokens.append(word.lower())\r\n",
        "    return tokens\r\n",
        "#Veri Setinin Doc2Vec Modeline Uygun Şekilde Tokenize Edilmesi\r\n",
        "train_tagged = train.apply(lambda r: TaggedDocument(words=tokenize_text(r['text']), tags=[r.labels]), axis=1)\r\n",
        "test_tagged = test.apply(lambda r: TaggedDocument(words=tokenize_text(r['text']), tags=[r.labels]), axis=1)\r\n",
        "tr_tags = [i.tags[0] for i in train_tagged]\r\n",
        "te_tags = [i.tags[0] for i in test_tagged] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI84_TWnYj0p"
      },
      "source": [
        "Modeli D-BOW ve DM modelleri için farklı epochlarda ve vektör uzunluklarında eğitip sonuçlarını gözlemliyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeuqdZmNYkXS"
      },
      "source": [
        "cores = multiprocessing.cpu_count()\r\n",
        "for vs in [50,75,100,150,200,250,300]:  \r\n",
        "  for epoch in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]:\r\n",
        "    for dm in [0,1]:\r\n",
        "      print('\\n','setting : ','dm : ', dm, 'vs : ', vs, 'num epochs : ', epoch)\r\n",
        "      model_dm = Doc2Vec(dm=dm, vector_size=vs, window=10, negative=5, min_count=1, workers=cores, alpha=0.0061, min_alpha = 0.0001)\r\n",
        "      model_dm.build_vocab([x for x in tqdm(train_tagged.values)])\r\n",
        "\r\n",
        "      for ep in range(epoch):\r\n",
        "        model_dm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\r\n",
        "        model_dm.alpha -= 0.0012\r\n",
        "        model_dm.min_alpha = model_dm.alpha\r\n",
        "      \r\n",
        "      train_embeddings = [] \r\n",
        "      for i in train_tagged:\r\n",
        "        embedding = model_dm.infer_vector(i.words, steps=20, alpha = 0.005)\r\n",
        "        train_embeddings.append(embedding)        \r\n",
        "\r\n",
        "      test_embeddings = [] \r\n",
        "      for i in test_tagged:\r\n",
        "        embedding = model_dm.infer_vector(i.words, steps=20, alpha = 0.005)\r\n",
        "        test_embeddings.append(embedding)     \r\n",
        "\r\n",
        "      LogReg_Results(train_embeddings,test_embeddings)\r\n",
        "      \r\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVeUU1oxYyWR"
      },
      "source": [
        "# LSTM Modeli ile AutoTagging Yapılması"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nItQpS0b9Iv"
      },
      "source": [
        "LSTM modeli için gereken parametreleri belirliyor ve tokenizerımızı oluşturuyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOi2bMi7aZ9T"
      },
      "source": [
        "# En Çok Kullanılan Kelimeler\r\n",
        "MAX_NB_WORDS = 50000\r\n",
        "# Modelimizin inputlarının maksimum uzunluğu.\r\n",
        "MAX_SEQUENCE_LENGTH = 250\r\n",
        "# Oluşacak olan Gömülerin Boyutu.\r\n",
        "EMBEDDING_DIM = 100\r\n",
        "\r\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\r\n",
        "tokenizer.fit_on_texts(train['text'].values)\r\n",
        "tokenizer.fit_on_texts(test['text'].values)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tfsNulWdzO2"
      },
      "source": [
        "Eğitim seti verisi ve etiketleri, Test seti verisi ve etiketlerinin boyutlarını atayıp gözlemliyoruz. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSBeZBT7dcw7"
      },
      "source": [
        "X = tokenizer.texts_to_sequences(train['text'].values)\r\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\r\n",
        "print('Shape of data tensor:', X.shape)\r\n",
        "\r\n",
        "X_tes = tokenizer.texts_to_sequences(test['text'].values)\r\n",
        "X_tes = pad_sequences(X_tes, maxlen=MAX_SEQUENCE_LENGTH)\r\n",
        "print('Shape of data tensor:', X_tes.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frOXB9v9dzmm"
      },
      "source": [
        "Derin öğrenme LSTM modelimizin katmanlarını oluşturuyoruz. Modelimizdeki etiket sayısı kadar dense katmanı parametresi değeri giriyoruz. Modelimizde 10 etiket olduğu için dense katmanımıza 10 değerini verdik."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZidWetWtd0Gn"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\r\n",
        "model.add(SpatialDropout1D(0.2))\r\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\r\n",
        "\r\n",
        "model.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mse'])\r\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYB3qkmXd5dB"
      },
      "source": [
        "Modelimizi 20 iterasyonda eğitiyor, daha sonra oluşan modeli test seti ile doğruluk kontrolüne tabi tutuyor, ürettiğimiz modeli kaydediyor ve sınıflandırma raporları için tahmin edilen değerler ile gerçek değerleri liste formatına sokuyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3qh7xqdd53Y"
      },
      "source": [
        "epochs = 20\r\n",
        "batch_size = 64\r\n",
        "history = model.fit(X, Y, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\r\n",
        "accr = model.evaluate(X_tes,Y_tes,return_dict=False)\r\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\r\n",
        "model.save('/LSTM10label/')\r\n",
        "y_pred=[]\r\n",
        "pred = model.predict(X_tes)\r\n",
        "for i in range(len(pred)):\r\n",
        "  y_pred.append([np.argmax(pred[i])])\r\n",
        "Y_pred = [item for sublist in y_pred for item in sublist]\r\n",
        "y_true = []\r\n",
        "for i in range(len(X_tes)):\r\n",
        "  y_true.append(Y_tes[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VX7uriVpWtz"
      },
      "source": [
        "Isı haritalaması yöntemi ile karmaşıklık matrisini oluşturuyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC3n5Wt9pC31"
      },
      "source": [
        "data = {'y_Actual':    y_true,\r\n",
        "        'y_Predicted': Y_pred\r\n",
        "        }\r\n",
        "\r\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\r\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\r\n",
        "\r\n",
        "sns.heatmap(confusion_matrix, annot=False,robust=False)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq9bLSaFpau6"
      },
      "source": [
        "Nümerik değerler ile karmaşıklık matrisini oluşturuyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmDiUHA8pbNc"
      },
      "source": [
        "confusion_matrix(y_true, Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALY-7dAEpkbP"
      },
      "source": [
        "Sınıflandırma raporunu oluşturuyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBrIjxvIpk0u"
      },
      "source": [
        "print(classification_report(y_true, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbR4dMPTpsaT"
      },
      "source": [
        "Yeni bir sorguda modelin tahminlediği cevabı gözlemlemek için aşağıdaki kodu kullanıyoruz. Ayrıca model alt parametrelerini de görüntüleyebiliyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYUmbiGnpslu"
      },
      "source": [
        "new_querry = ['googleda reklam vermek istiyorum']\r\n",
        "new_querry=cleanText(new_querry)\r\n",
        "seq = X_test[0] \r\n",
        "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\r\n",
        "pred = model.predict(padded)\r\n",
        "print(seq)\r\n",
        "print(padded)\r\n",
        "print(pred, labels[np.argmax(pred)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6E8mw3aqy3z"
      },
      "source": [
        "# BERT-İnceAyarlama Yöntemi ile AutoTagging Yapılması"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wExQP5qrE1k"
      },
      "source": [
        "Bert için üretilmiş base uncased(küçük harf, noktalama işaretleri ve sembollerden arınmış) modeli(https://huggingface.co/loodos/bert-base-turkish-uncased) kendi veri setimiz ile ince ayar yapmak için aşağıdaki parametreleri kullanıyoruz. 3 epochta iterasyon yapıyoruz. Sınıflandırma modelini tercih ediyoruz. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL2akSzQv-Gk"
      },
      "source": [
        "model_args = {\r\n",
        "    \"use_early_stopping\": True,\r\n",
        "    \"early_stopping_delta\": 0.01,\r\n",
        "    \"early_stopping_metric\": \"mcc\",\r\n",
        "    \"early_stopping_metric_minimize\": False,\r\n",
        "    \"early_stopping_patience\": 5,\r\n",
        "    \"evaluate_during_training_steps\": 1000,\r\n",
        "    \"fp16\": False,\r\n",
        "    \"num_train_epochs\":3\r\n",
        "}\r\n",
        "\r\n",
        "model = ClassificationModel(\r\n",
        "    \"bert\", \r\n",
        "    \"dbmdz/bert-base-turkish-uncased\",\r\n",
        "     use_cuda=True, \r\n",
        "     args=model_args, \r\n",
        "     num_labels=10\r\n",
        ")\r\n",
        "model.train_model(train, acc=sklearn.metrics.accuracy_score,output_dir='/BERT-finetune-10labels-questions/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBGcVsaOxze0"
      },
      "source": [
        "İnce ayar yaptığımız BERT modelini çağırıyoruz ve ürettiğimiz etiketlere göre modelin test setimizi tahminlemesi için gereken yapıyı oluşturuyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az5BxDEPxzwx"
      },
      "source": [
        "code_to_label={}\r\n",
        "for i in range(10):\r\n",
        "  code_to_label.update({'LABEL_%s'%i: i})\r\n",
        "tokenizer= AutoTokenizer.from_pretrained(\"/BERT-finetune-10labels-questions/checkpoint-3621-epoch-3\")\r\n",
        "\r\n",
        "# Ürettiğimiz modeli yüklüyoruz\r\n",
        "model= AutoModelForSequenceClassification.from_pretrained(\"/BERT-finetune-10labels-questions/checkpoint-3621-epoch-3\")\r\n",
        "\r\n",
        "# Tahminleme modelini oluşturuyoruz\r\n",
        "nlp=pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\r\n",
        "code_to_label=code_to_label\r\n",
        "\r\n",
        "print(nlp(\"reklam vermek\"))\r\n",
        "print(code_to_label[nlp(\"nasıl reklam verebilirim\")[0]['label']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUxo86wyVe0"
      },
      "source": [
        "Test setimizdeki verileri ürettiğimiz tahminleme yapısından geçirip sonuçları karşılaştırmak için raporluyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cCJgObMyV9P"
      },
      "source": [
        "all_count = 0\r\n",
        "true_count = 0\r\n",
        "y_pred = []\r\n",
        "y_true = []\r\n",
        "for i in range(len(test['text'])):\r\n",
        "  x_pred=None\r\n",
        "  x_pred=code_to_label[nlp(test['text'][i])[0]['label']]\r\n",
        "  y_pred.append(x_pred)\r\n",
        "for i in range(len(test['text'])):\r\n",
        "  y_true.append(test['labels'][i])\r\n",
        "print(classification_report(y_true, y_pred))\r\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}